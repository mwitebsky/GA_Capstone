{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Chicago Departures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1997113, 50)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Assets/Datasets/BTS_flight_data/Processed/chicago_departures.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get time in Date/Hour to match hourly weather data\n",
    "cols = [['CRS_DEP_DATETIME', 'CRS_DEP_DATEHOUR'],\n",
    "        ['CRS_ARR_DATETIME', 'CRS_ARR_DATEHOUR'],\n",
    "        ['PRIOR_CRS_DEP_DATETIME', 'PRIOR_CRS_DEP_DATEHOUR']]\n",
    "\n",
    "for col in cols:\n",
    "    df[col[0]] = pd.to_datetime( df[col[0]], infer_datetime_format=True)\n",
    "    df[col[1]] = df[col[0]].apply(lambda x: datetime(x.year, x.month, x.day, x.hour))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Origin Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import and format weather data\n",
    "orig_weather = pd.read_csv('../Assets/Datasets/Weather/Clean_Dep_Weather_Hourly.csv')\n",
    "orig_weather = orig_weather[['Airport', 'DateTime', 'Daypart', 'Temp', 'Visibility', 'Wind Speed',\n",
    "                   'Precip', 'Conditions']]\n",
    "orig_weather = orig_weather.rename(columns = {'DateTime' : 'DateHour',\n",
    "                                              'Temp': 'Orig_Temp',\n",
    "                                              'Visibility' : 'Orig_Visibility',\n",
    "                                              'Wind Speed' : 'Orig_Wind Speed',\n",
    "                                              'Precip' : 'Orig_Precip',\n",
    "                                              'Conditions' : 'Orig_Conditions'})\n",
    "orig_weather['DateHour'] = pd.to_datetime(orig_weather['DateHour'], infer_datetime_format=True)\n",
    "\n",
    "# Remove leading 'K' from airport to match df airport codes \n",
    "orig_weather['Airport'] = orig_weather['Airport'].apply(lambda x: x[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create origin airport weather columns for 3 hours before and 2 hours after\n",
    "orig_weather = orig_weather.sort_values(['Airport', 'DateHour'])\n",
    "offsets = [['B1_', 1], ['B2_', 2], ['B3_', 3], ['A1_', -1], ['A2_', -2]]\n",
    "cols = ['Orig_Temp', 'Orig_Visibility', 'Orig_Wind Speed', 'Orig_Precip', 'Orig_Conditions']\n",
    "\n",
    "for offset in offsets:\n",
    "    for col in cols:\n",
    "        orig_weather[offset[0]+col] = orig_weather[col].shift(offset[1])\n",
    "        \n",
    "orig_weather.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# format BTS data to match weather columns for join\n",
    "code_match = pd.read_csv('../Assets/Datasets/BTS_flight_data/Match_Tables/AIRPORT_ID_CODE.csv')\n",
    "df = pd.merge(df, code_match[['US_DOT_AIRPORT_ID', 'US_DOT_AIRPORT_CODE']], \n",
    "              left_on='ORIGIN_AIRPORT_ID', right_on='US_DOT_AIRPORT_ID',\n",
    "              how= 'left')\n",
    "df.drop('US_DOT_AIRPORT_ID', axis=1, inplace=True)\n",
    "df = df.rename(columns = {'US_DOT_AIRPORT_CODE':'ORIGIN_AIRPORT_CODE'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# join weather and BTS on dep airport and departure time\n",
    "df = pd.merge(df, orig_weather, how='left',\n",
    "              left_on=['ORIGIN_AIRPORT_CODE', 'CRS_DEP_DATEHOUR'],\n",
    "              right_on=['Airport', 'DateHour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1991998, 86)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove rows that have no weather info \n",
    "df.dropna(subset=['Airport'], inplace=True)\n",
    "df.drop('Airport', axis= 1, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Destination Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import and format weather data\n",
    "dest_weather = pd.read_csv('../Assets/Datasets/Weather/Clean_Arr_Weather_Hourly.csv')\n",
    "dest_weather = dest_weather[['Airport', 'DateTime', 'Daypart', 'Temp', 'Visibility', 'Wind Speed',\n",
    "                   'Precip', 'Conditions']]\n",
    "dest_weather = dest_weather.rename(columns = {'DateTime' : 'DateHour',\n",
    "                                              'Temp': 'Dest_Temp',\n",
    "                                              'Visibility' : 'Dest_Visibility',\n",
    "                                              'Wind Speed' : 'Dest_Wind Speed',\n",
    "                                              'Precip' : 'Dest_Precip',\n",
    "                                              'Conditions' : 'Dest_Conditions'})\n",
    "dest_weather['DateHour'] = pd.to_datetime(dest_weather['DateHour'], infer_datetime_format=True)\n",
    "\n",
    "# Remove leading 'K' from airport to match df airport codes \n",
    "dest_weather['Airport'] = dest_weather['Airport'].apply(lambda x: x[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create destination airport weather columns for 3 hours before and 2 hours after\n",
    "dest_weather = dest_weather.sort_values(['Airport', 'DateHour'])\n",
    "\n",
    "offsets = [['B1_', 1], ['B2_', 2], ['B3_', 3], ['A1_', -1], ['A2_', -2]]\n",
    "cols = ['Dest_Temp', 'Dest_Visibility', 'Dest_Wind Speed', 'Dest_Precip', 'Dest_Conditions']\n",
    "\n",
    "for offset in offsets:\n",
    "    for col in cols:\n",
    "        dest_weather[offset[0]+col] = dest_weather[col].shift(offset[1])\n",
    "        \n",
    "dest_weather.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# format BTS data to match weather columns for join\n",
    "df = pd.merge(df, code_match[['US_DOT_AIRPORT_ID', 'US_DOT_AIRPORT_CODE']], \n",
    "              left_on='DEST_AIRPORT_ID', right_on='US_DOT_AIRPORT_ID',\n",
    "              how= 'left')\n",
    "df.drop('US_DOT_AIRPORT_ID', axis=1, inplace=True)\n",
    "df = df.rename(columns = {'US_DOT_AIRPORT_CODE':'DEST_AIRPORT_CODE'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# join weather and BTS on dest airport and Arrival Time\n",
    "df = pd.merge(df, dest_weather, how='left',\n",
    "              left_on=['DEST_AIRPORT_CODE', 'CRS_ARR_DATEHOUR'],\n",
    "              right_on=['Airport', 'DateHour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove rows that have no weather (will drop any dest with no weather)\n",
    "df.dropna(subset=['Airport'], inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Prior Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import and format weather data\n",
    "prior_weather = pd.read_csv('../Assets/Datasets/Weather/Clean_Arr_Weather_Hourly.csv')\n",
    "prior_weather = prior_weather[['Airport', 'DateTime', 'Daypart', 'Temp', 'Visibility', 'Wind Speed',\n",
    "                   'Precip', 'Conditions']]\n",
    "prior_weather = prior_weather.rename(columns = {'DateTime' : 'DateHour',\n",
    "                                              'Temp': 'Prior_Temp',\n",
    "                                              'Visibility' : 'Prior_Visibility',\n",
    "                                              'Wind Speed' : 'Prior_Wind Speed',\n",
    "                                              'Precip' : 'Prior_Precip',\n",
    "                                              'Conditions' : 'Prior_Conditions'})\n",
    "prior_weather['DateHour'] = pd.to_datetime(prior_weather['DateHour'], infer_datetime_format=True)\n",
    "\n",
    "# Remove leading 'K' from airport to match df airport codes \n",
    "prior_weather['Airport'] = prior_weather['Airport'].apply(lambda x: x[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create prior airport weather columns for 3 hours before and 2 hours after\n",
    "prior_weather = prior_weather.sort_values(['Airport', 'DateHour'])\n",
    "\n",
    "offsets = [['B1_', 1], ['B2_', 2], ['B3_', 3], ['A1_', -1], ['A2_', -2]]\n",
    "cols = ['Prior_Temp', 'Prior_Visibility', 'Prior_Wind Speed', 'Prior_Precip', 'Prior_Conditions']\n",
    "\n",
    "for offset in offsets:\n",
    "    for col in cols:\n",
    "        prior_weather[offset[0]+col] = prior_weather[col].shift(offset[1])\n",
    "        \n",
    "prior_weather.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# format BTS data to match weather columns for join\n",
    "df = pd.merge(df, code_match[['US_DOT_AIRPORT_ID', 'US_DOT_AIRPORT_CODE']], \n",
    "              left_on='PRIOR_AIRPORT', right_on='US_DOT_AIRPORT_ID',\n",
    "              how= 'left')\n",
    "df.drop('US_DOT_AIRPORT_ID', axis=1, inplace=True)\n",
    "df = df.rename(columns = {'US_DOT_AIRPORT_CODE':'PRIOR_AIRPORT_CODE'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# join weather and BTS on prior airport and prior dep time\n",
    "df = pd.merge(df, prior_weather, how='left',\n",
    "              left_on=['PRIOR_AIRPORT_CODE', 'PRIOR_CRS_DEP_DATEHOUR'],\n",
    "              right_on=['Airport', 'DateHour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46914, 120)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove rows that have no weather (will drop any dest with no weather)\n",
    "df.dropna(subset=['Airport'], inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Airplane Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import airplane info\n",
    "tail_match = pd.read_csv('../Assets/Datasets/FlightTracker_Airplane/FA_Airplane_Info_Clean.csv')\n",
    "tail_match.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# left join data with tail match\n",
    "df = pd.merge(df, tail_match, left_on='TAIL_NUM', right_on='N-NUMBER', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46620, 125)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop data that has no airplane match\n",
    "df.dropna(subset=['mfr'], inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change Prior Airport from ID to Code\n",
    "# format BTS data to match weather columns for join\n",
    "df = pd.merge(df, code_match[['US_DOT_AIRPORT_ID', 'US_DOT_AIRPORT_CODE']], \n",
    "              left_on='PRIOR_AIRPORT', right_on='US_DOT_AIRPORT_ID',\n",
    "              how= 'left')\n",
    "df.drop('US_DOT_AIRPORT_ID', axis=1, inplace=True)\n",
    "df = df.rename(columns = {'US_DOT_AIRPORT_CODE':'PRIOR_AIRPORT_CODE'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Delay_Time</th>\n",
       "      <th>Count</th>\n",
       "      <th>Sum</th>\n",
       "      <th>pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>26156</td>\n",
       "      <td>26156.0</td>\n",
       "      <td>0.561047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Delay_Time  Count      Sum       pct\n",
       "0         0.0  26156  26156.0  0.561047"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Find cutoff for .5% longest delays (210 minutes)\n",
    "# delays = pd.DataFrame(df['ARR_DELAY_NEW'].value_counts()).reset_index().sort_values('index')\n",
    "# cumsum = delays.cumsum()\n",
    "# cumsum.columns = ['delay_time', 'Sum']\n",
    "# delays = delays.join(cumsum['Sum'])\n",
    "# delays.columns = ['Delay_Time', 'Count', 'Sum']\n",
    "# delays['pct'] = delays['Sum'] / df.shape[0]\n",
    "# delays[delays['Delay_Time'] == 0]\n",
    "\n",
    "# Cap Delays at 210 minutes (top .5% of delays)\n",
    "df['ARR_DELAY_NEW'] = df['ARR_DELAY_NEW'].apply(lambda x: 210 if x > 210 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cap Delta_Time_min at 360 minutes. should cover almost all delta times \n",
    "df['DELTA_TIME_MIN'] = df['DELTA_TIME_MIN'].apply(lambda x: 360 if x > 360 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create categorical delay\n",
    "df['DEP_DELAY_C'] = df['DEP_DELAY_NEW'].apply(lambda x: 0 if x < 1 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select Columns necessary for model\n",
    "data = df[[\n",
    "           'ORIGIN_AIRPORT_CODE','DAILY_DEPARTURES', 'HOURLY_DEPARTURES', 'UNIQUE_CARRIER', 'DEST_AIRPORT_ID', \n",
    "           'DELTA_TIME_MIN','CRS_DEP_YEAR','CRS_DEP_WEEK','CRS_DEP_DAY_OF_WEEK','CRS_DEP_TIME_hours',\n",
    "           'Orig_Temp','Orig_Visibility','Orig_Wind Speed','Orig_Precip',\n",
    "           'B1_Orig_Temp','B1_Orig_Visibility','B1_Orig_Wind Speed','B1_Orig_Precip',\n",
    "           'B2_Orig_Temp','B2_Orig_Visibility','B2_Orig_Wind Speed','B2_Orig_Precip',\n",
    "           'B3_Orig_Temp','B3_Orig_Visibility','B3_Orig_Wind Speed','B3_Orig_Precip',\n",
    "           'A1_Orig_Temp','A1_Orig_Visibility','A1_Orig_Wind Speed','A1_Orig_Precip',\n",
    "           'A2_Orig_Temp','A2_Orig_Visibility','A2_Orig_Wind Speed','A2_Orig_Precip',\n",
    "#            'Dest_Temp','Dest_Visibility','Dest_Wind Speed','Dest_Precip',\n",
    "#            'B1_Dest_Temp','B1_Dest_Visibility','B1_Dest_Wind Speed','B1_Dest_Precip',\n",
    "#            'B2_Dest_Temp','B2_Dest_Visibility','B2_Dest_Wind Speed','B2_Dest_Precip',\n",
    "#            'B3_Dest_Temp','B3_Dest_Visibility','B3_Dest_Wind Speed','B3_Dest_Precip',\n",
    "#            'A1_Dest_Temp','A1_Dest_Visibility','A1_Dest_Wind Speed','A1_Dest_Precip',\n",
    "#            'A2_Dest_Temp','A2_Dest_Visibility','A2_Dest_Wind Speed','A2_Dest_Precip',\n",
    "           'Prior_Temp','Prior_Visibility','Prior_Wind Speed','Prior_Precip',\n",
    "           'B1_Prior_Temp','B1_Prior_Visibility','B1_Prior_Wind Speed','B1_Prior_Precip',\n",
    "           'B2_Prior_Temp','B2_Prior_Visibility','B2_Prior_Wind Speed','B2_Prior_Precip',\n",
    "           'B3_Prior_Temp','B3_Prior_Visibility','B3_Prior_Wind Speed','B3_Prior_Precip',\n",
    "           'A1_Prior_Temp','A1_Prior_Visibility','A1_Prior_Wind Speed','A1_Prior_Precip',\n",
    "           'A2_Prior_Temp','A2_Prior_Visibility','A2_Prior_Wind Speed','A2_Prior_Precip',\n",
    "           'Model', 'mfr_year',\n",
    "            # 'PRIOR_AIRPORT_CODE', 'DEST_AIRPORT_CODE\n",
    "           'DEP_DELAY_C'\n",
    "          ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_names(lst):\n",
    "    new_lst = []\n",
    "    for item in lst:\n",
    "        item = item.lower()\n",
    "        item = item.replace(' ', '_')\n",
    "        new_lst.append(item)\n",
    "    return new_lst\n",
    "\n",
    "data.columns = clean_names(list(data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Random Forest Create Dummies\n",
    "#to_str = ['crs_dep_day_of_week', 'crs_dep_time_hours', 'crs_dep_week', 'crs_dep_year']\n",
    "# for item in to_str:\n",
    "#     data.loc[:, item] = data[item].astype(str)\n",
    "\n",
    "data = pd.get_dummies(data, \n",
    "               columns=[\n",
    "                        'unique_carrier', 'dest_airport_id', 'model'\n",
    "                       ], \n",
    "               drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split data by airport\n",
    "mdw = data[data['origin_airport_code'] == 'MDW']\n",
    "ohr = data[data['origin_airport_code'] == 'ORD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mdw: (13908, 187)\n",
      "ohr (18725, 187)\n"
     ]
    }
   ],
   "source": [
    "# Create train & test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "mdw_x = mdw.drop(['origin_airport_code', 'dep_delay_c'], axis=1)\n",
    "mdw_y = mdw['dep_delay_c']\n",
    "\n",
    "mdw_x_train, mdw_x_test, mdw_y_train, mdw_y_test = train_test_split(mdw_x, mdw_y, train_size=.7)\n",
    "print 'mdw: {}'.format(mdw_x_train.shape)\n",
    "\n",
    "ohr_x = ohr.drop(['origin_airport_code', 'dep_delay_c'], axis=1)\n",
    "ohr_y = ohr['dep_delay_c']\n",
    "\n",
    "ohr_x_train, ohr_x_test, ohr_y_train, ohr_y_test = train_test_split(ohr_x, ohr_y, train_size=.7)\n",
    "print 'ohr {}'.format(ohr_x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Low features model\n",
    "# data = df[['crs_dep_hour', 'delta_time_min', 'origin_airport_id', 'unique_carrier', 'week', 'temp', 'dep_delay_c']]\n",
    "\n",
    "# data = pd.get_dummies(data, \n",
    "#                columns=['crs_dep_hour', 'origin_airport_id', 'unique_carrier', 'week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # KNN/Neural Create dummy variables \n",
    "# to_str = ['day_of_week', 'prior_airport', 'origin_airport_id', 'dest_airport_id']\n",
    "# for item in to_str:\n",
    "#     data.loc[:, item] = data[item].astype(str)\n",
    "\n",
    "# data = pd.get_dummies(data, \n",
    "#                columns=[\n",
    "        \n",
    "#                         'week', 'day_of_week',  \n",
    "#                         'unique_carrier', 'prior_airport', 'origin_airport_id', 'dest_airport_id', \n",
    "#                         'model',  \n",
    "#                        ], \n",
    "#                drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Create x and y and train test splits\n",
    "\n",
    "\n",
    "# # Sample data\n",
    "# sample = data.sample(frac=.2)\n",
    "\n",
    "# x = sample.drop('dep_delay_c', axis=1)\n",
    "# y = sample['dep_delay_c']\n",
    "\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=.7)\n",
    "# x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Standardize for KNN or Neural\n",
    "# # standardize\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# ss = StandardScaler()\n",
    "\n",
    "# ss.fit(x_train)\n",
    "# x_train = ss.transform(x_train)\n",
    "# x_test = ss.trasform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(x_train)\n",
    "print 'Total variance explained:\\n{}\\n'.format(sum(pca.explained_variance_ratio_))\n",
    "print 'Variance breakdown:\\n{}'.format(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train = pca.transform(x_train)\n",
    "x_test = pca.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .66 is baseline of flights that are delayed <= 5 Min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mlp = MLPClassifier()\n",
    "mlp.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mlp.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest & KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.727279263733\n",
      "Test Score: 0.704076497232\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier MDW\n",
    "clf = RandomForestClassifier(n_estimators = 100, min_samples_leaf=40,  n_jobs=-1)\n",
    "clf.fit(mdw_x_train, mdw_y_train)\n",
    "print 'Train Score: {}'.format(clf.score(mdw_x_train, mdw_y_train))\n",
    "print 'Test Score: {}'.format(clf.score(mdw_x_test, mdw_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>crs_dep_time_hours</td>\n",
       "      <td>0.225760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>delta_time_min</td>\n",
       "      <td>0.156953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>crs_dep_year</td>\n",
       "      <td>0.028438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hourly_departures</td>\n",
       "      <td>0.024777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>b1_orig_temp</td>\n",
       "      <td>0.016893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crs_dep_week</td>\n",
       "      <td>0.012458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>orig_temp</td>\n",
       "      <td>0.011710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>daily_departures</td>\n",
       "      <td>0.009839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>b1_orig_wind_speed</td>\n",
       "      <td>0.008683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>orig_wind_speed</td>\n",
       "      <td>0.007871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>crs_dep_day_of_week</td>\n",
       "      <td>0.006295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>b1_orig_visibility</td>\n",
       "      <td>0.003641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>orig_visibility</td>\n",
       "      <td>0.003559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>b1_orig_precip</td>\n",
       "      <td>0.000063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>orig_precip</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Feature  Importance\n",
       "6    crs_dep_time_hours    0.225760\n",
       "2        delta_time_min    0.156953\n",
       "3          crs_dep_year    0.028438\n",
       "1     hourly_departures    0.024777\n",
       "11         b1_orig_temp    0.016893\n",
       "4          crs_dep_week    0.012458\n",
       "7             orig_temp    0.011710\n",
       "0      daily_departures    0.009839\n",
       "13   b1_orig_wind_speed    0.008683\n",
       "9       orig_wind_speed    0.007871\n",
       "5   crs_dep_day_of_week    0.006295\n",
       "12   b1_orig_visibility    0.003641\n",
       "8       orig_visibility    0.003559\n",
       "14       b1_orig_precip    0.000063\n",
       "10          orig_precip    0.000016"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest Feature importances MDW\n",
    "f_imp = pd.DataFrame(zip(mdw_x_train.columns,clf.feature_importances_), columns=['Feature', 'Importance'])\n",
    "f_imp.head(15).sort_values(['Importance'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_delay</th>\n",
       "      <th>delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>predict_no_delay</th>\n",
       "      <td>4971</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict_delay</th>\n",
       "      <td>1788</td>\n",
       "      <td>5144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  no_delay  delay\n",
       "predict_no_delay      4971   2005\n",
       "predict_delay         1788   5144"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion Matrix MDW\n",
    "predictions = clf.predict(mdw_x_train)\n",
    "cm = confusion_matrix(mdw_y_train, predictions)\n",
    "cm = pd.DataFrame(cm, columns=['no_delay', 'delay'], index= ['predict_no_delay', 'predict_delay'])\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.693511348465\n",
      "Test Score: 0.653501121356\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier ORD\n",
    "clf = RandomForestClassifier(n_estimators = 100, min_samples_leaf=50,  n_jobs=-1)\n",
    "clf.fit(ohr_x_train, ohr_y_train)\n",
    "print 'Train Score: {}'.format(clf.score(ohr_x_train, ohr_y_train))\n",
    "print 'Test Score: {}'.format(clf.score(ohr_x_test, ohr_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>crs_dep_time_hours</td>\n",
       "      <td>0.159649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>delta_time_min</td>\n",
       "      <td>0.106123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>crs_dep_year</td>\n",
       "      <td>0.033632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hourly_departures</td>\n",
       "      <td>0.029207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>orig_temp</td>\n",
       "      <td>0.026252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crs_dep_week</td>\n",
       "      <td>0.026245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>b1_orig_temp</td>\n",
       "      <td>0.023741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>daily_departures</td>\n",
       "      <td>0.022847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>b1_orig_wind_speed</td>\n",
       "      <td>0.015853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>orig_wind_speed</td>\n",
       "      <td>0.011138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>b1_orig_visibility</td>\n",
       "      <td>0.009633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>orig_visibility</td>\n",
       "      <td>0.009088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>crs_dep_day_of_week</td>\n",
       "      <td>0.007167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>b1_orig_precip</td>\n",
       "      <td>0.005970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>orig_precip</td>\n",
       "      <td>0.003263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Feature  Importance\n",
       "6    crs_dep_time_hours    0.159649\n",
       "2        delta_time_min    0.106123\n",
       "3          crs_dep_year    0.033632\n",
       "1     hourly_departures    0.029207\n",
       "7             orig_temp    0.026252\n",
       "4          crs_dep_week    0.026245\n",
       "11         b1_orig_temp    0.023741\n",
       "0      daily_departures    0.022847\n",
       "13   b1_orig_wind_speed    0.015853\n",
       "9       orig_wind_speed    0.011138\n",
       "12   b1_orig_visibility    0.009633\n",
       "8       orig_visibility    0.009088\n",
       "5   crs_dep_day_of_week    0.007167\n",
       "14       b1_orig_precip    0.005970\n",
       "10          orig_precip    0.003263"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest Feature importances ORD\n",
    "f_imp = pd.DataFrame(zip(ohr_x_train.columns,clf.feature_importances_), columns=['Feature', 'Importance'])\n",
    "f_imp.head(15).sort_values(['Importance'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_delay</th>\n",
       "      <th>delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>predict_no_delay</th>\n",
       "      <td>5282</td>\n",
       "      <td>3598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict_delay</th>\n",
       "      <td>2141</td>\n",
       "      <td>7704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  no_delay  delay\n",
       "predict_no_delay      5282   3598\n",
       "predict_delay         2141   7704"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion Matrix ORD\n",
    "predictions = clf.predict(ohr_x_train)\n",
    "cm = confusion_matrix(ohr_y_train, predictions)\n",
    "cm = pd.DataFrame(cm, columns=['no_delay', 'delay'], index= ['predict_no_delay', 'predict_delay'])\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# KNN\n",
    "clf = KNeighborsClassifier(n_neighbors=5, n_jobs=-1)\n",
    "clf.fit(x_train, y_train)\n",
    "print 'Train Score: {}'.format(clf.score(x_train, y_train))\n",
    "print 'Test Score: {}'.format(clf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extra Trees Classifier\n",
    "clf = ExtraTreesClassifier(n_estimators = 100, min_samples_leaf=50,  n_jobs=-1)\n",
    "clf.fit(x_train, y_train)\n",
    "print 'Train Score: {}'.format(clf.score(x_train, y_train))\n",
    "print 'Test Score: {}'.format(clf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "cr = classification_report(y_train, predictions)\n",
    "print cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## WIP -- to model likely prior airport\n",
    "prior_group = df[df['YEAR'] == 2016].groupby(['YEAR', 'ORIGIN_AIRPORT_ID', 'UNIQUE_CARRIER', 'FL_NUM']).agg(\n",
    "                                                {'PRIOR_AIRPORT': pd.Series.nunique,\n",
    "                                                'DEST_AIRPORT_ID' : pd.Series.nunique}).reset_index()\n",
    "\n",
    "prior_group['PRIOR_AIRPORT'].value_counts()\n",
    "# prior_group['FL_NUM'] = prior_group['FL_NUM'].astype(str)\n",
    "# prior_group['Route'] = prior_group['UNIQUE_CARRIER'] + prior_group['FL_NUM']\n",
    "\n",
    "# sns.barplot(x='Route', y='PRIOR_AIRPORT', data=prior_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [lesson01]",
   "language": "python",
   "name": "Python [lesson01]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
