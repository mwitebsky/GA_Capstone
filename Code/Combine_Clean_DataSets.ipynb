{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "from datetime import date, datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# locate all csv files in directory\n",
    "directory = '../Assets/Datasets/BTS_flight_data/Raw'\n",
    "\n",
    "file_names = []\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"): \n",
    "        file_names.append(os.path.join(directory, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# combine all csvs in pandas\n",
    "dataframes = []\n",
    "ct = 1\n",
    "files = len(file_names)\n",
    "for csv in file_names:\n",
    "    dataframes.append(pd.read_csv(csv))\n",
    "    ct += 1\n",
    "\n",
    "df = pd.concat(dataframes)\n",
    "df.reset_index(inplace=True)\n",
    "df.drop('index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_csv('../Assets/Datasets/BTS_flight_data/Processed/raw_combined.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove cancelled flights and diverted flights\n",
    "df = df[(df['CANCELLED'] == 0) & (df['DIVERTED'] == 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Times and Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 2400 isn't a real time, replace with 2359. Remove decimal points\n",
    "columns = ['DEP_TIME', 'ARR_TIME', 'CRS_DEP_TIME', 'CRS_ARR_TIME']\n",
    "for column in columns:\n",
    "    df[column] = df[column].astype(int)\n",
    "    df[column] = df[column].apply(lambda x: 2359 if x > 2359 else x)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ****TAKES A FEW MINUTES****\n",
    "# Calculate Departure and Arrival Dates\n",
    "df['FL_DATE'] = pd.to_datetime(df['FL_DATE'], infer_datetime_format=True)\n",
    "\n",
    "# Increases day by one if departure time is 5 hours before arrival time\n",
    "df['FL_ARR_DATE'] = np.where(df['CRS_DEP_TIME'] - df['CRS_ARR_TIME'] > 5,\n",
    "                            df['FL_DATE'].apply(lambda x: x + DateOffset(days=1)), df['FL_DATE'])\n",
    "\n",
    "df = df.rename(columns = {'FL_DATE':'FL_DEP_DATE'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pull year, month, day out of arr_date and dep_date\n",
    "new_df = pd.DataFrame()\n",
    "columns = ['FL_ARR_DATE', 'FL_DEP_DATE']\n",
    "for column in columns:\n",
    "    new_df[column+'_Year'] = df[column].apply(lambda x: x.year)\n",
    "    new_df[column+'_Month'] = df[column].apply(lambda x: x.month)\n",
    "    new_df[column+'_Day'] = df[column].apply(lambda x: x.day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create hour and minute columns for dep and arrival times\n",
    "columns = ['DEP_TIME', 'ARR_TIME', 'CRS_DEP_TIME', 'CRS_ARR_TIME']\n",
    "for column in columns:    \n",
    "    new_df[column+'_hours'] = df[column]/100\n",
    "    new_df[column+'_hours'] = new_df[column+'_hours'].astype(int)\n",
    "    new_df[column+'_mins'] = df[column]%100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# **** TAKES A LONG TIME ****\n",
    "#Create DateTime columns for dep and arrivals\n",
    "\n",
    "# ARR_DATETIME\n",
    "temp_df = pd.DataFrame()\n",
    "temp_df['Year'] = new_df['FL_ARR_DATE_Year']\n",
    "temp_df['Month'] = new_df['FL_ARR_DATE_Month']\n",
    "temp_df['Day'] = new_df['FL_ARR_DATE_Day']\n",
    "temp_df['Hour'] = new_df['ARR_TIME_hours']\n",
    "temp_df['Minute'] = new_df['ARR_TIME_mins']\n",
    "new_df['ARR_DATETIME'] = temp_df.apply(lambda s: datetime(*s),axis = 1)\n",
    "\n",
    "\n",
    "# CRS_ARR_DATETIME\n",
    "temp_df['Hour'] = new_df['CRS_ARR_TIME_hours']\n",
    "temp_df['Minute'] = new_df['CRS_ARR_TIME_mins']\n",
    "new_df['CRS_ARR_DATETIME'] = temp_df.apply(lambda s: datetime(*s),axis = 1)\n",
    "\n",
    "\n",
    "# DEP_DATETIME\n",
    "temp_df = pd.DataFrame()\n",
    "temp_df['Year'] = new_df['FL_DEP_DATE_Year']\n",
    "temp_df['Month'] = new_df['FL_DEP_DATE_Month']\n",
    "temp_df['Day'] = new_df['FL_DEP_DATE_Day']\n",
    "temp_df['Hour'] = new_df['DEP_TIME_hours']\n",
    "temp_df['Minute'] = new_df['DEP_TIME_mins']\n",
    "new_df['DEP_DATETIME'] = temp_df.apply(lambda s: datetime(*s),axis = 1)\n",
    "\n",
    "\n",
    "# CRS_DEP_DATETIME\n",
    "temp_df['Hour'] = new_df['CRS_DEP_TIME_hours']\n",
    "temp_df['Minute'] = new_df['CRS_DEP_TIME_mins']\n",
    "new_df['CRS_DEP_DATETIME'] = temp_df.apply(lambda s: datetime(*s),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Rearrange new_df\n",
    "new_df = new_df[['ARR_DATETIME', 'FL_ARR_DATE_Year', 'FL_ARR_DATE_Day', \n",
    "                 'DEP_DATETIME', 'FL_DEP_DATE_Year', 'FL_DEP_DATE_Day',\n",
    "                 'CRS_ARR_DATETIME', 'CRS_DEP_TIME_hours', 'CRS_ARR_TIME_hours',\n",
    "                 'CRS_DEP_DATETIME', 'DEP_TIME_hours', 'ARR_TIME_hours',]]\n",
    "new_df = new_df.rename(columns = {'FL_ARR_DATE_Year' : 'ARR_DATE_YEAR',\n",
    "                                  'FL_ARR_DATE_Day' : 'ARR_DATE_DAY',\n",
    "                                  'FL_DEP_DATE_Year' : 'DEP_DATE_YEAR',\n",
    "                                  'FL_DEP_DATE_Day' : 'DEP_DATE_DAY'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Join columns and remove repeat columns\n",
    "df = df.join(new_df, how='left')\n",
    "df.drop(['YEAR', 'MONTH', 'DAY_OF_MONTH', 'DAY_OF_WEEK', 'FL_DEP_DATE', 'CRS_DEP_TIME', 'DEP_TIME',\n",
    "        'CRS_ARR_TIME', 'ARR_TIME', 'Unnamed: 35', 'FL_ARR_DATE'], axis=1, inplace=True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Actual and scheduled Chicago Departures/Arrival Times\n",
    "df['CHI_ARR-DEP_TIME'] = np.where(((df['ORIGIN_AIRPORT_ID'] == 13930) | (df['ORIGIN_AIRPORT_ID'] == 13232)),\n",
    "                                        df['DEP_DATETIME'], df['ARR_DATETIME'])\n",
    "df['CRS_CHI_ARR-DEP_TIME'] = np.where(((df['ORIGIN_AIRPORT_ID'] == 13930) | (df['ORIGIN_AIRPORT_ID'] == 13232)),\n",
    "                                      df['CRS_DEP_DATETIME'], df['CRS_ARR_DATETIME'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tail Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove null TAIL_NUM rows\n",
    "df.dropna(subset=['TAIL_NUM'], inplace=True)\n",
    "df.reset_index(inplace=True)\n",
    "df.drop('index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove departures with a non-n tail number\n",
    "df = df[df['TAIL_NUM'].str[0] == 'N']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Adjust TAIL_NUM to fit FAA specs\n",
    "## An N-number can be in any of these formats\n",
    "## One to five digits (N12345)\n",
    "## One to four digits followed by one letter (N1234Z)\n",
    "## One to three digits followed by two letters (N123AZ)\n",
    "## N-numbers do not have\n",
    "## A zero (0) as the first number\n",
    "## The letters \"I\" or \"O\"\n",
    "\n",
    "def remove_leading_0(n_num):\n",
    "    if n_num[1] != '0':\n",
    "        return 'N'+ n_num[1:]     \n",
    "    else:\n",
    "        return remove_leading_0(n_num[1:])\n",
    "\n",
    "df['TAIL_NUM'] = df.loc[:, 'TAIL_NUM'].apply(remove_leading_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get list of all tail numbers\n",
    "tails = df['TAIL_NUM'].unique()\n",
    "tails = pd.DataFrame(tails)\n",
    "tails.columns = ['TailNum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create fixed tail num match table (some tail numbers in BTS data are incorrect)\n",
    "match = pd.read_csv('../Assets/Datasets/n_num_match/n_num_match.csv')\n",
    "match = match[['TailNum', 'TailNum_fixed']]\n",
    "\n",
    "tails = pd.merge(tails, match, on='TailNum', how='left')\n",
    "tails.fillna('Missing', inplace=True)\n",
    "tails['TailNum_fixed'] = np.where(tails['TailNum_fixed'] == 'Missing', tails['TailNum'], tails['TailNum_fixed'])\n",
    "tails.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Join Fixed tails to df\n",
    "df = pd.merge(df, tails, how='left', left_on='TAIL_NUM', right_on='TailNum')\n",
    "df.drop(['TailNum', 'TAIL_NUM'], axis=1, inplace=True)\n",
    "df = df.rename(columns = {'TailNum_fixed' : 'TAIL_NUM'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace CANCELLATION CODE nulls with 'N'\n",
    "df['CANCELLATION_CODE'].fillna('N', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Prior Airport and Prior Dep Time with Tail Num and Chicago CRS Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find prior airport and scheduled time dif beteween landing in chicago and departing\n",
    "df = df.sort_values(['TAIL_NUM', 'CHI_ARR-DEP_TIME'])\n",
    "df_2 = df[['TAIL_NUM', 'ORIGIN_AIRPORT_ID', 'DEST_AIRPORT_ID', 'CHI_ARR-DEP_TIME',\n",
    "           'CRS_CHI_ARR-DEP_TIME', 'CRS_DEP_DATETIME']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Assigns prior column by shifting one row back\n",
    "df_2.loc[:, 'PRIOR_DEST_ID'] = df_2['DEST_AIRPORT_ID'].shift()\n",
    "df_2.loc[:, 'PRIOR_ORIG_ID'] = df_2['ORIGIN_AIRPORT_ID'].shift()\n",
    "df_2.loc[:, 'PRIOR_TAIL_NUM'] = df_2['TAIL_NUM'].shift()\n",
    "df_2.loc[:, 'PRIOR_CHI_ARR-DEP_TIME'] = df_2['CHI_ARR-DEP_TIME'].shift()\n",
    "df_2.loc[:, 'PRIOR_CRS_CHI_ARR-DEP_TIME'] = df_2['CRS_CHI_ARR-DEP_TIME'].shift()\n",
    "df_2.loc[:, 'PRIOR_CRS_DEP_DATETIME'] = df_2['CRS_DEP_DATETIME'].shift()\n",
    "df_2.loc[:, 'PRIOR_AIRPORT'] = 0\n",
    "\n",
    "\n",
    "# remove first row, has null priors\n",
    "df_2 = df_2.iloc[1:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add PRIOR_AIRPORT column\n",
    "df_2['PRIOR_AIRPORT'] = np.where(((df_2['ORIGIN_AIRPORT_ID'] == 13930) | (df_2['ORIGIN_AIRPORT_ID'] == 13232)) &\n",
    "                                 (df_2['PRIOR_DEST_ID'] == df_2['ORIGIN_AIRPORT_ID']) &\n",
    "                                 (df_2['TAIL_NUM'] == df_2['PRIOR_TAIL_NUM']), \n",
    "                                 df_2['PRIOR_ORIG_ID'], 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_pa = pd.DataFrame(df_2[['PRIOR_AIRPORT', 'PRIOR_CRS_DEP_DATETIME', 'PRIOR_CRS_CHI_ARR-DEP_TIME']])\n",
    "df = df.join(df_pa, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2037344, 43)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove departures with no PRIOR_AIRPORT (83515 rows)\n",
    "df = df[df['PRIOR_AIRPORT'] != 0]\n",
    "df = df.iloc[1:, :]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time between arriving in Chicago and departing from Chicago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find difference between scheduled landing and taking off by tailnum\n",
    "df['DELTA_TIME'] = df['CRS_CHI_ARR-DEP_TIME'] - df['PRIOR_CRS_CHI_ARR-DEP_TIME']\n",
    "df['DELTA_TIME_MIN'] = (df['DELTA_TIME'].apply(lambda x: x.days *24*60) + \n",
    "                          df['DELTA_TIME'].apply(lambda x: x.seconds / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove rows where delta_time_min <= 0 (~40,000)\n",
    "# There shouldn't be flights scheduled to depart before the plane arrives\n",
    "df = df[df['DELTA_TIME_MIN'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ensure departures from MDW & ORD only\n",
    "df = df[df['ORIGIN_AIRPORT_ID'].isin([13930, 13232])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add CRS_DEP time parts\n",
    "df['CRS_DEP_WEEK'] = df['CRS_DEP_DATETIME'].apply(lambda x: x.week)\n",
    "df['CRS_DEP_DAY_OF_WEEK'] = df['CRS_DEP_DATETIME'].apply(lambda x: x.dayofweek)\n",
    "df['CRS_DEP_YEAR'] = df['DEP_DATE_YEAR']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Departures per day and hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create scheduled departures per day\n",
    "daily_flights = df.groupby(['ORIGIN_AIRPORT_ID', 'CRS_DEP_YEAR',\n",
    "                            'CRS_DEP_WEEK', 'CRS_DEP_DAY_OF_WEEK'])['CRS_DEP_DATETIME'].count()\n",
    "daily_flights = daily_flights.reset_index()\n",
    "daily_flights = daily_flights.rename(columns = {'CRS_DEP_DATETIME' : 'DAILY_DEPARTURES'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Merge daily scheduled departures to df\n",
    "df = pd.merge(df, daily_flights, \n",
    "              on=['ORIGIN_AIRPORT_ID', 'CRS_DEP_YEAR','CRS_DEP_WEEK', 'CRS_DEP_DAY_OF_WEEK'],\n",
    "              how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create scheduled departures per hour\n",
    "daily_flights = df.groupby(['ORIGIN_AIRPORT_ID', 'CRS_DEP_YEAR',\n",
    "                            'CRS_DEP_WEEK', 'CRS_DEP_DAY_OF_WEEK', 'CRS_DEP_TIME_hours'])['CRS_DEP_DATETIME'].count()\n",
    "daily_flights = daily_flights.reset_index()\n",
    "daily_flights = daily_flights.rename(columns = {'CRS_DEP_DATETIME' : 'HOURLY_DEPARTURES'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge hourly scheduled departures to df\n",
    "df = pd.merge(df, daily_flights, \n",
    "              on=['ORIGIN_AIRPORT_ID', 'CRS_DEP_YEAR','CRS_DEP_WEEK', 'CRS_DEP_DAY_OF_WEEK', 'CRS_DEP_TIME_hours'],\n",
    "              how='left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create MDW & ORD departures\n",
    "df.to_csv('../Assets/Datasets/BTS_flight_data/Processed/chicago_departures.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [lesson01]",
   "language": "python",
   "name": "Python [lesson01]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
