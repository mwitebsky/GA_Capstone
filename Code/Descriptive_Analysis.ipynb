{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Assets/Datasets/BTS_flight_data/Processed/raw_combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df[(df['ORIGIN_AIRPORT_ID'] == 13930) | (df['ORIGIN_AIRPORT_ID'] == 13232)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2164076, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "departures = df[['FL_DATE', 'DAY_OF_WEEK', 'UNIQUE_CARRIER', 'TAIL_NUM', 'ORIGIN_AIRPORT_ID', \n",
    "                 'DEST_AIRPORT_ID', 'CRS_DEP_TIME', 'DEP_DELAY_NEW', 'CANCELLED', 'DIVERTED']]\n",
    "departures.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mwitebsky/anaconda2/envs/lesson01/lib/python2.7/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "departures['Status'] = np.where(departures['CANCELLED'] == 1, 'Cancelled', \n",
    "                                np.where(departures['DIVERTED'] == 1, 'Diverted',\n",
    "                                         np.where(departures['DEP_DELAY_NEW'] > 0, 'Delayed', 'On-Time')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "On-Time      1102583\n",
       "Delayed       996703\n",
       "Cancelled      59450\n",
       "Diverted        5340\n",
       "Name: Status, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "departures['Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "code_match = pd.read_csv('../Assets/Datasets/BTS_flight_data/Match_Tables/AIRPORT_ID_CODE.csv')\n",
    "departures = pd.merge(departures, code_match[['US_DOT_AIRPORT_ID', 'US_DOT_AIRPORT_CODE']], \n",
    "              left_on='ORIGIN_AIRPORT_ID', right_on='US_DOT_AIRPORT_ID',\n",
    "              how= 'left')\n",
    "departures.drop('US_DOT_AIRPORT_ID', axis=1, inplace=True)\n",
    "departures = departures.rename(columns = {'US_DOT_AIRPORT_CODE':'ORIGIN_AIRPORT_CODE'})\n",
    "\n",
    "departures = pd.merge(departures, code_match[['US_DOT_AIRPORT_ID', 'US_DOT_AIRPORT_CODE']], \n",
    "              left_on='DEST_AIRPORT_ID', right_on='US_DOT_AIRPORT_ID',\n",
    "              how= 'left')\n",
    "departures.drop('US_DOT_AIRPORT_ID', axis=1, inplace=True)\n",
    "departures = departures.rename(columns = {'US_DOT_AIRPORT_CODE':'DEST_AIRPORT_CODE'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "departures.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "carrier_match = pd.read_csv('../Assets/Datasets/BTS_flight_data/Match_Tables/L_UNIQUE_CARRIERS.csv')\n",
    "\n",
    "departures = pd.merge(departures, carrier_match, \n",
    "                      left_on='UNIQUE_CARRIER', right_on='Code',\n",
    "                      how='left')\n",
    "\n",
    "departures.drop(['UNIQUE_CARRIER', 'ORIGIN_AIRPORT_ID', 'DEST_AIRPORT_ID', 'Code'], axis=1, inplace=True)\n",
    "departures = departures.rename(columns = {'Description' : 'Airline'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Replace Tail Num of cancelled flights without TN\n",
    "departures['TAIL_NUM'] = np.where((departures['TAIL_NUM'].isnull()) &  (departures['CANCELLED'] == 1),\n",
    "                                  'NOTAIL', departures['TAIL_NUM'])\n",
    "\n",
    "# remove departures with a non-n tail number (<100 flights)\n",
    "departures = departures[departures['TAIL_NUM'].str[0] == 'N']\n",
    "\n",
    "# Adjust TAIL_NUM to fit FAA specs\n",
    "## An N-number can be in any of these formats\n",
    "## One to five digits (N12345)\n",
    "## One to four digits followed by one letter (N1234Z)\n",
    "## One to three digits followed by two letters (N123AZ)\n",
    "## N-numbers do not have\n",
    "## A zero (0) as the first number\n",
    "## The letters \"I\" or \"O\"\n",
    "\n",
    "def remove_leading_0(n_num):\n",
    "    if n_num[1] != '0':\n",
    "        return 'N'+ n_num[1:]     \n",
    "    else:\n",
    "        return remove_leading_0(n_num[1:])\n",
    "\n",
    "departures['TAIL_NUM'] = departures.loc[:, 'TAIL_NUM'].apply(remove_leading_0)\n",
    "\n",
    "# get list of all tail numbers\n",
    "tails = departures['TAIL_NUM'].unique()\n",
    "tails = pd.DataFrame(tails)\n",
    "tails.columns = ['TailNum']\n",
    "\n",
    "# Create fixed tail num match table (some tail numbers in BTS data are incorrect)\n",
    "match = pd.read_csv('../Assets/Datasets/n_num_match/n_num_match.csv')\n",
    "match = match[['TailNum', 'TailNum_fixed']]\n",
    "\n",
    "tails = pd.merge(tails, match, on='TailNum', how='left')\n",
    "tails.fillna('Missing', inplace=True)\n",
    "tails['TailNum_fixed'] = np.where(tails['TailNum_fixed'] == 'Missing', tails['TailNum'], tails['TailNum_fixed'])\n",
    "tails.drop_duplicates(inplace=True)\n",
    "\n",
    "# Join Fixed tails to departures\n",
    "departures = pd.merge(departures, tails, how='left', left_on='TAIL_NUM', right_on='TailNum')\n",
    "departures.drop(['TailNum', 'TAIL_NUM'], axis=1, inplace=True)\n",
    "departures = departures.rename(columns = {'TailNum_fixed' : 'TAIL_NUM'})\n",
    "\n",
    "# import airplane info\n",
    "tail_match = pd.read_csv('../Assets/Datasets/FlightTracker_Airplane/FA_Airplane_Info_Clean.csv')\n",
    "tail_match.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "# left join data with tail match\n",
    "departures = pd.merge(departures, tail_match, left_on='TAIL_NUM', right_on='N-NUMBER', how='left')\n",
    "\n",
    "departures.drop('TAIL_NUM', axis=1, inplace=True)\n",
    "departures = departures.rename(columns = {'N-NUMBER' : 'TAIL_NUM'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "departures['Route'] = departures['ORIGIN_AIRPORT_CODE'] + ' - ' + departures['DEST_AIRPORT_CODE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add datetime and hour\n",
    "departures['FL_DATE'] = pd.to_datetime(departures['FL_DATE'], infer_datetime_format=True)\n",
    "new_df = pd.DataFrame()\n",
    "new_df['Year'] = departures['FL_DATE'].apply(lambda x: x.year)\n",
    "new_df['Month'] = departures['FL_DATE'].apply(lambda x: x.month)\n",
    "new_df['Day'] = departures['FL_DATE'].apply(lambda x: x.day)\n",
    "new_df['Hour'] = departures['CRS_DEP_TIME']/100\n",
    "new_df['Hour'] = new_df['Hour'].astype(int)\n",
    "new_df['Minute'] = departures['CRS_DEP_TIME']%100\n",
    "new_df['CRS_DEP_DATETIME'] = new_df.apply(lambda s: datetime(*s),axis = 1)\n",
    "departures = departures.join(new_df[['CRS_DEP_DATETIME', 'Hour', 'Year']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "actives = departures.groupby(['Year', 'ORIGIN_AIRPORT_CODE', 'Airline'])['CRS_DEP_DATETIME'].count().reset_index()\n",
    "actives_2016 = actives[actives['Year'] == 2016][['ORIGIN_AIRPORT_CODE', 'Airline']]\n",
    "actives_2016['Active'] = 'Active'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "departures = pd.merge(departures, actives_2016, on=['ORIGIN_AIRPORT_CODE', 'Airline'], how='left')\n",
    "departures = departures.fillna(value=({'Active' : 'Inactive'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add Airport Location Data and Name\n",
    "columns = ['Airport ID', 'Name', 'City', 'Country', 'IATA/FAA', 'ICAO', 'Latitude', 'Longitude', 'Altitude',\n",
    "           'Timezone', 'DST', 'Tz']\n",
    "airport_match = pd.read_csv('../Assets/Datasets/Open_Flights/airports_match.csv', names=columns)\n",
    "\n",
    "departures = pd.merge(departures, airport_match[['IATA/FAA', 'Name', 'Latitude', 'Longitude']],\n",
    "                     left_on='ORIGIN_AIRPORT_CODE', right_on='IATA/FAA', how='left')\n",
    "departures = departures.rename(columns = {'Name' : 'Orig_Name'})\n",
    "departures = pd.merge(departures, airport_match[['IATA/FAA', 'Name', 'Latitude', 'Longitude']],\n",
    "                     left_on='DEST_AIRPORT_CODE', right_on='IATA/FAA', how='left')\n",
    "departures.drop(['IATA/FAA_x', 'IATA/FAA_y'], axis=1, inplace=True)\n",
    "departures = departures.rename(columns = {'Name' : 'Dest_Name',\n",
    "                                          'Latitude_x' : 'Latitude_O',\n",
    "                                          'Longitude_x' : 'Longitude_O',\n",
    "                                          'Latitude_y' : 'Latitude_D',\n",
    "                                          'Longitude_y' : 'Longitude_D'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "departures.drop('FL_DATE', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "departures.to_csv('../Assets/Datasets/Outputs/chi_dep_viz.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "departures.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "departures.groupby([''])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [lesson01]",
   "language": "python",
   "name": "Python [lesson01]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
